{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b67ebd66",
      "metadata": {
        "id": "b67ebd66"
      },
      "source": [
        "https://colab.research.google.com/github/Anutri03/eye/blob/main/new_blood_vessel.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "514e19a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "514e19a7",
        "outputId": "b97be21d-4b56-48bb-92aa-d32e6fba74dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'eye'...\n",
            "remote: Enumerating objects: 234, done.\u001b[K\n",
            "remote: Counting objects: 100% (234/234), done.\u001b[K\n",
            "remote: Compressing objects: 100% (225/225), done.\u001b[K\n",
            "remote: Total 234 (delta 15), reused 228 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (234/234), 32.86 MiB | 17.94 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "/content/eye/eye\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Anutri03/eye.git\n",
        "%cd eye\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8b1235d8",
      "metadata": {
        "id": "8b1235d8"
      },
      "outputs": [],
      "source": [
        "import os##\n",
        "import cv2\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from operator import add\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2b22a5f",
      "metadata": {
        "id": "e2b22a5f"
      },
      "source": [
        "### Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "587cb251",
      "metadata": {
        "id": "587cb251"
      },
      "outputs": [],
      "source": [
        "class DriveDataset(Dataset):\n",
        "    def __init__(self, images_path, masks_path):\n",
        "\n",
        "        self.images_path = images_path\n",
        "        self.masks_path = masks_path\n",
        "        self.n_samples = len(images_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Reading image \"\"\"\n",
        "        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n",
        "        image = image/255.0\n",
        "        image = np.transpose(image, (2, 0, 1))\n",
        "        image = image.astype(np.float32)\n",
        "        image = torch.from_numpy(image)\n",
        "\n",
        "        \"\"\" Reading mask \"\"\"\n",
        "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
        "        mask = mask/255.0\n",
        "        mask = np.expand_dims(mask, axis=0)\n",
        "        mask = mask.astype(np.float32)\n",
        "        mask = torch.from_numpy(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb5ca318",
      "metadata": {
        "id": "fb5ca318"
      },
      "source": [
        "### Unet helper classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7f07053b",
      "metadata": {
        "id": "7f07053b"
      },
      "outputs": [],
      "source": [
        "# Build Conv_layer\n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "035531d3",
      "metadata": {
        "id": "035531d3"
      },
      "outputs": [],
      "source": [
        "# Build Encoder section\n",
        "class encoder_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = conv_block(in_c, out_c)\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        p = self.pool(x)\n",
        "\n",
        "        return x, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ab892219",
      "metadata": {
        "id": "ab892219"
      },
      "outputs": [],
      "source": [
        "# Build Decoder section\n",
        "class decoder_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
        "        self.conv = conv_block(out_c+out_c, out_c)\n",
        "\n",
        "    def forward(self, inputs, skip):\n",
        "        x = self.up(inputs)\n",
        "        x = torch.cat([x, skip], axis=1)\n",
        "        x = self.conv(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "23d54f4b",
      "metadata": {
        "id": "23d54f4b"
      },
      "outputs": [],
      "source": [
        "# Build Unet architecture\n",
        "class build_unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.e1 = encoder_block(3, 64)\n",
        "        self.e2 = encoder_block(64, 128)\n",
        "        self.e3 = encoder_block(128, 256)\n",
        "        self.e4 = encoder_block(256, 512)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.b = conv_block(512, 1024)\n",
        "\n",
        "        # Decoder\n",
        "        self.d1 = decoder_block(1024, 512)\n",
        "        self.d2 = decoder_block(512, 256)\n",
        "        self.d3 = decoder_block(256, 128)\n",
        "        self.d4 = decoder_block(128, 64)\n",
        "\n",
        "        # Classifier\n",
        "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Encoder\n",
        "        s1, p1 = self.e1(inputs)\n",
        "        s2, p2 = self.e2(p1)\n",
        "        s3, p3 = self.e3(p2)\n",
        "        s4, p4 = self.e4(p3)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.b(p4)\n",
        "\n",
        "        # Decoder\n",
        "        d1 = self.d1(b, s4)\n",
        "        d2 = self.d2(d1, s3)\n",
        "        d3 = self.d3(d2, s2)\n",
        "        d4 = self.d4(d3, s1)\n",
        "\n",
        "        outputs = self.outputs(d4)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9e681ba",
      "metadata": {
        "id": "e9e681ba"
      },
      "source": [
        "### Losses classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f84731aa",
      "metadata": {
        "id": "f84731aa"
      },
      "outputs": [],
      "source": [
        "# Dice Coefficient\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "        return 1 - dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1762eb7a",
      "metadata": {
        "id": "1762eb7a"
      },
      "outputs": [],
      "source": [
        "# Dice Binary Cross Entropy Coefficient\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        Dice_BCE = BCE + dice_loss\n",
        "\n",
        "        return Dice_BCE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbeb7de2",
      "metadata": {
        "id": "cbeb7de2"
      },
      "source": [
        "### Function to seed the randomness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2a86fd79",
      "metadata": {
        "id": "2a86fd79"
      },
      "outputs": [],
      "source": [
        "def seeding(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b2823e1",
      "metadata": {
        "id": "2b2823e1"
      },
      "source": [
        "### new dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "11b3243f",
      "metadata": {
        "id": "11b3243f"
      },
      "outputs": [],
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4915607",
      "metadata": {
        "id": "b4915607"
      },
      "source": [
        "### Function to calculate the taken time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "98bc8134",
      "metadata": {
        "id": "98bc8134"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04f46569",
      "metadata": {
        "id": "04f46569"
      },
      "source": [
        "### Function to train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3f62e109",
      "metadata": {
        "id": "3f62e109"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, loss_fn, device):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, dtype=torch.float32)\n",
        "        y = y.to(device, dtype=torch.float32)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss = epoch_loss/len(loader)\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd7ffcf",
      "metadata": {
        "id": "edd7ffcf"
      },
      "source": [
        "### Function to evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "288742be",
      "metadata": {
        "id": "288742be"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, loss_fn, device):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device, dtype=torch.float32)\n",
        "            y = y.to(device, dtype=torch.float32)\n",
        "\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        epoch_loss = epoch_loss / len(loader)\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e03dcf5a",
      "metadata": {
        "id": "e03dcf5a"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0154f5f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0154f5f4",
        "outputId": "4bc956a4-f4ea-434f-f106-1a5023349248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Size:\n",
            "Train: 80 - Valid: 20\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Seeding\n",
        "seeding(42)\n",
        "\n",
        "# Create files directory to store checkpoint file\n",
        "create_dir(\"files\")\n",
        "\n",
        "#  Get data paths\n",
        "train_x = sorted(glob(\"/content/eye/Data/train/image/*\"))\n",
        "train_y = sorted(glob(\"/content/eye/Data/train/mask/*\"))\n",
        "\n",
        "valid_x = sorted(glob(\"/content/eye/Data/test/image/*\"))\n",
        "valid_y = sorted(glob(\"/content/eye/Data/test/mask/*\"))\n",
        "\n",
        "data_str = f\"Dataset Size:\\nTrain: {len(train_x)} - Valid: {len(valid_x)}\\n\"\n",
        "print(data_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set hyperparameters"
      ],
      "metadata": {
        "id": "3gk4Ttyazrpa"
      },
      "id": "3gk4Ttyazrpa"
    },
    {
      "cell_type": "code",
      "source": [
        "H = 512\n",
        "W = 512\n",
        "size = (H, W)\n",
        "batch_size = 2\n",
        "lr = 1e-4\n",
        "checkpoint_path = \"files/checkpoint.pth\""
      ],
      "metadata": {
        "id": "ngLPh-CJzuog"
      },
      "id": "ngLPh-CJzuog",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DriveDataset(train_x, train_y)\n",
        "valid_dataset = DriveDataset(valid_x, valid_y)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "Ee_uDcpxzxj_"
      },
      "id": "Ee_uDcpxzxj_",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unet Model"
      ],
      "metadata": {
        "id": "glUZaJAWz1I5"
      },
      "id": "glUZaJAWz1I5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set cuda device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Build model\n",
        "model = build_unet()\n",
        "model = model.to(device)\n",
        "\n",
        "# Set Optimizer and Loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
        "loss_fn = DiceBCELoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XggZucMQz4T1",
        "outputId": "df50ddc5-8619-4e97-e265-a78273874096"
      },
      "id": "XggZucMQz4T1",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model train\n",
        "\n",
        "\n",
        "best_valid_loss = float(\"inf\")\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
        "    valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
        "\n",
        "    # Saving the model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        print(f\"Valid loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}. Saving checkpoint: {checkpoint_path}\")\n",
        "\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    data_str = f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n'\n",
        "    data_str += f'\\tTrain Loss: {train_loss:.3f}\\n'\n",
        "    data_str += f'\\tVal. Loss: {valid_loss:.3f}\\n'\n",
        "    print(data_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAuwFdZLz5iw",
        "outputId": "af9432be-161f-40ff-ea80-c3d58f7d31a1"
      },
      "id": "NAuwFdZLz5iw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss improved from inf to 1.3119. Saving checkpoint: files/checkpoint.pth\n",
            "Epoch: 01 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 1.180\n",
            "\tVal. Loss: 1.312\n",
            "\n",
            "Valid loss improved from 1.3119 to 0.9459. Saving checkpoint: files/checkpoint.pth\n",
            "Epoch: 02 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.986\n",
            "\tVal. Loss: 0.946\n",
            "\n",
            "Valid loss improved from 0.9459 to 0.9094. Saving checkpoint: files/checkpoint.pth\n",
            "Epoch: 03 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.923\n",
            "\tVal. Loss: 0.909\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5g9M91fdz9Ar"
      },
      "id": "5g9M91fdz9Ar",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}